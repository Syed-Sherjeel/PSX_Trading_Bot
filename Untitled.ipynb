{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from copy import deepcopy\n",
    "from keras.layers import *\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from datetime import datetime\n",
    "from keras.layers import Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATRL</th>\n",
       "      <th>bahl</th>\n",
       "      <th>EPCL</th>\n",
       "      <th>FCCL</th>\n",
       "      <th>LUCK</th>\n",
       "      <th>MCB</th>\n",
       "      <th>MLCF</th>\n",
       "      <th>NETSOL</th>\n",
       "      <th>NML</th>\n",
       "      <th>OGDC</th>\n",
       "      <th>PPL</th>\n",
       "      <th>PSO</th>\n",
       "      <th>SEARL</th>\n",
       "      <th>TRG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82.90</td>\n",
       "      <td>26.50</td>\n",
       "      <td>22.75</td>\n",
       "      <td>6.70</td>\n",
       "      <td>51.35</td>\n",
       "      <td>144.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>17.40</td>\n",
       "      <td>31.01</td>\n",
       "      <td>73.85</td>\n",
       "      <td>176.75</td>\n",
       "      <td>200.80</td>\n",
       "      <td>64.05</td>\n",
       "      <td>1.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83.30</td>\n",
       "      <td>26.58</td>\n",
       "      <td>23.00</td>\n",
       "      <td>6.70</td>\n",
       "      <td>51.25</td>\n",
       "      <td>144.17</td>\n",
       "      <td>4.98</td>\n",
       "      <td>17.45</td>\n",
       "      <td>31.30</td>\n",
       "      <td>74.00</td>\n",
       "      <td>177.00</td>\n",
       "      <td>200.99</td>\n",
       "      <td>64.00</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85.00</td>\n",
       "      <td>26.90</td>\n",
       "      <td>22.90</td>\n",
       "      <td>6.75</td>\n",
       "      <td>51.50</td>\n",
       "      <td>144.49</td>\n",
       "      <td>5.05</td>\n",
       "      <td>17.40</td>\n",
       "      <td>31.20</td>\n",
       "      <td>73.70</td>\n",
       "      <td>177.30</td>\n",
       "      <td>201.03</td>\n",
       "      <td>63.10</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85.40</td>\n",
       "      <td>27.02</td>\n",
       "      <td>23.19</td>\n",
       "      <td>6.70</td>\n",
       "      <td>51.85</td>\n",
       "      <td>145.00</td>\n",
       "      <td>5.08</td>\n",
       "      <td>17.50</td>\n",
       "      <td>31.05</td>\n",
       "      <td>73.80</td>\n",
       "      <td>177.33</td>\n",
       "      <td>201.12</td>\n",
       "      <td>60.80</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86.85</td>\n",
       "      <td>28.10</td>\n",
       "      <td>23.11</td>\n",
       "      <td>6.74</td>\n",
       "      <td>51.85</td>\n",
       "      <td>145.00</td>\n",
       "      <td>5.17</td>\n",
       "      <td>17.26</td>\n",
       "      <td>30.80</td>\n",
       "      <td>73.70</td>\n",
       "      <td>176.80</td>\n",
       "      <td>201.45</td>\n",
       "      <td>62.00</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ATRL   bahl   EPCL  FCCL   LUCK     MCB  MLCF  NETSOL    NML   OGDC  \\\n",
       "0  82.90  26.50  22.75  6.70  51.35  144.00  5.00   17.40  31.01  73.85   \n",
       "1  83.30  26.58  23.00  6.70  51.25  144.17  4.98   17.45  31.30  74.00   \n",
       "2  85.00  26.90  22.90  6.75  51.50  144.49  5.05   17.40  31.20  73.70   \n",
       "3  85.40  27.02  23.19  6.70  51.85  145.00  5.08   17.50  31.05  73.80   \n",
       "4  86.85  28.10  23.11  6.74  51.85  145.00  5.17   17.26  30.80  73.70   \n",
       "\n",
       "      PPL     PSO  SEARL   TRG  \n",
       "0  176.75  200.80  64.05  1.37  \n",
       "1  177.00  200.99  64.00  1.40  \n",
       "2  177.30  201.03  63.10  1.38  \n",
       "3  177.33  201.12  60.80  1.31  \n",
       "4  176.80  201.45  62.00  1.40  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('../MPT Data/Combined.csv')\n",
    "df.drop(['TRADE_ENTRY_DATE','Unnamed: 0'],axis=1,inplace=True)\n",
    "for _,columns in enumerate(df):\n",
    "    df[[columns]]=df[[columns]].astype('float')\n",
    "df.columns=['ATRL','bahl','EPCL','FCCL','LUCK','MCB','MLCF','NETSOL','NML',\n",
    "      'OGDC','PPL','PSO','SEARL','TRG']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trader function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trader(X,nS3,share_price1,share_price2):\n",
    "    '''\n",
    "    This function takes cash,Number of shares\n",
    "    Share price at minimum and share price at maximum\n",
    "    and returns the remaining amount\n",
    "    '''\n",
    "    #Selling shares at maximum point in 100 entries\n",
    "    Amount_Gained=((nS3*share_price2)*.2)\n",
    "    Brocker_fee=((nS3*share_price2)*.2)*.3*.01\n",
    "    nS3=nS3-(nS3*.2)\n",
    "    X=X+Amount_Gained-Brocker_fee\n",
    "    #Buying shares at minimum point in 100 entries\n",
    "    Shares_bought=(.997*Amount_Gained)/share_price1\n",
    "    nS3=nS3+Shares_bought\n",
    "    X=X-(.997*Amount_Gained)\n",
    "    return X,math.floor(nS3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=250\n",
    "X=2000\n",
    "tpf=98000\n",
    "TN=X+tpf\n",
    "df1=df\n",
    "shares1={'ATRL': 0,'bahl': 0,'EPCL': 0,'FCCL': 0,'LUCK': 0,'MCB': 0,\n",
    " 'MLCF': 0,'NETSOL': 0,'NML': 0,'OGDC': 0,'PPL': 0,'PSO': 0,\n",
    " 'SEARL': 0,'TRG': 0}\n",
    "Min={'ATRL': 0,'bahl': 0,'EPCL': 0,'FCCL': 0,'LUCK': 0,'MCB': 0,\n",
    " 'MLCF': 0,'NETSOL': 0,'NML': 0,'OGDC': 0,'PPL': 0,'PSO': 0,\n",
    " 'SEARL': 0,'TRG': 0}\n",
    "Max={'ATRL': 0,'bahl': 0,'EPCL': 0,'FCCL': 0,'LUCK': 0,'MCB': 0,\n",
    " 'MLCF': 0,'NETSOL': 0,'NML': 0,'OGDC': 0,'PPL': 0,'PSO': 0,\n",
    " 'SEARL': 0,'TRG': 0}\n",
    "for share in shares1:\n",
    "    shares1[share]=math.floor(7000/df1.loc[0,share])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN=[100000]\n",
    "df2=df\n",
    "for i in range(df2.shape[0]//lm-1):\n",
    "    df1=df2[i*lm:(i*lm)+lm]\n",
    "    for share in shares1:\n",
    "        Min[share]=df1[share].idxmin()\n",
    "        Max[share]=df1[share].idxmax()\n",
    "    for share in shares1:\n",
    "        if Min[share]!=Max[share]:\n",
    "           X,shares1[share]=trader(X,shares1[share],df2.loc[Min[share],share],df2.loc[Max[share],share])\n",
    "           tpf+=(df2.loc[(i*lm)+lm,share]*shares1[share])\n",
    "           TN.append(X+tpf)\n",
    "           print(X,tpf)\n",
    "    tpf=0\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=[]\n",
    "test_data=[]\n",
    "for share in shares1:\n",
    "    train_data.append(df.loc[:299999,share])\n",
    "    test_data.append(df.loc[300000:400000,share])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Data\n",
    "Now you need to define a scaler to normalize the data. MinMaxScalar scales all the data to be in the region of 0 and 1. You can also reshape the training and test data to be in the shape [data_size, num_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "for i in range(len(shares1)):\n",
    "    train_data[i] = train_data[i].values.reshape(-1,1)\n",
    "    test_data[i] = test_data[i].values.reshape(-1,1)\n",
    "td=train_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the observation we made earlier, that is, different time periods of data have different value ranges, you normalize the data by splitting the full series into windows. If you don't do this, the earlier data will be close to 0 and will not add much value to the learning process. Here you choose a window size of 25000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Scaler with training data and smooth data\n",
    "train_data_norm=[]\n",
    "smoothing_window_size = 200\n",
    "\n",
    "for i in range(len(shares1)):\n",
    "    train_data_acq=td[i].copy() \n",
    "    for di in range(0,300000,smoothing_window_size):\n",
    "        scaler.fit(train_data_acq[di:di+smoothing_window_size,:])\n",
    "        train_data_acq[di:di+smoothing_window_size,:] = scaler.transform(train_data_acq[di:di+smoothing_window_size,:])\n",
    "    train_data_norm.append(train_data_acq)\n",
    "#Normalize the test data too\n",
    "   # test_data[i]=scaler.fit(test_data[i]).transform(test_data[i]).reshape(-1)\n",
    "# Reshape both train and test data\n",
    "for i in range(len(shares1)):\n",
    "    train_data_norm[i] = train_data_norm[i].reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Train and test data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt=[]\n",
    "yt=[]\n",
    "X_train_comb = []\n",
    "y_train_comb = [] \n",
    "for j in range(len(shares1)):\n",
    "    Xt,yt=[],[]\n",
    "    for i in range(60, len(train_data_norm[j])):\n",
    "        Xt.append(train_data[j][i-60:i])\n",
    "        yt.append(train_data[j][i])\n",
    "    \n",
    "    Xt, yt = np.array(Xt), np.array(yt)\n",
    "    Xt = np.reshape(Xt, (Xt.shape[0], Xt.shape[1], 1))\n",
    "    X_train_comb.append(Xt)\n",
    "    y_train_comb.append(yt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt=[]\n",
    "yt=[]\n",
    "X_test_comb = []\n",
    "y_test_comb = [] \n",
    "for j in range(len(shares1)):\n",
    "    Xt,yt=[],[]\n",
    "    for i in range(60, len(test_data[j])):\n",
    "        Xt.append(test_data[j][i-60:i])\n",
    "        yt.append(test_data[j][i])\n",
    "    \n",
    "    Xt, yt = np.array(Xt), np.array(yt)\n",
    "    Xt = np.reshape(Xt, (Xt.shape[0], Xt.shape[1], 1))\n",
    "    X_train_comb.append(Xt)\n",
    "    y_train_comb.append(yt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    regressor = Sequential()\n",
    "\n",
    "    regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (60, 1)))\n",
    "    regressor.add(Dropout(0.2))\n",
    "\n",
    "    regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "    regressor.add(Dropout(0.2))\n",
    "\n",
    "    regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "    regressor.add(Dropout(0.2))\n",
    "\n",
    "    regressor.add(LSTM(units = 50))\n",
    "    regressor.add(Dropout(0.2))\n",
    "\n",
    "    regressor.add(Dense(units = 1))\n",
    "\n",
    "    regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "    \n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing initialization of 14 models for 14 stocks and MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[]\n",
    "MAPE={'ATRL': 0,'bahl': 0,'EPCL': 0,'FCCL': 0,'LUCK': 0,'MCB': 0,\n",
    " 'MLCF': 0,'NETSOL': 0,'NML': 0,'OGDC': 0,'PPL': 0,'PSO': 0,\n",
    " 'SEARL': 0,'TRG': 0}\n",
    "for share in shares1:\n",
    "    models.append(model()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "109/500 [=====>........................] - ETA: 3:39 - loss: 18326.2363"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-00a62343d5ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshares1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_comb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_comb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(0,len(shares1)):\n",
    "    models[i].fit(X_train_comb[i],y_train_comb[i],epochs=10,batch_size=600) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299940"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_comb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
