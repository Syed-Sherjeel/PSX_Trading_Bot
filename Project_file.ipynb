{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<center>Stock Market Trading Bot</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "* [OHLC Data]() \n",
    "    * [Loading Data](#OHLC_Load)\n",
    "    * [Plotting Data](#Plt)\n",
    "    * [Descriptive Statistics](#desc)\n",
    "    * [Inferential Statistics](#Inf)\n",
    "    * [Trading FrameWork](#Tf)\n",
    "    * [Trade Log](#Tl)\n",
    "    * [Unit Testing](#Ut)\n",
    "* [Per Trade Data]()\n",
    "    * [Loading Data](#pt)\n",
    "    * [Combining Date Time](#dt)\n",
    "    * [Cleaning Data](#Clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib as mpl\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Data Source](https://www.kaggle.com/ghazanfarali/ksedataset?select=UBL.csv) \n",
    "[Data Source](https://www.kaggle.com/arsalanjaved/pakistan-stock-exchange)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data <a name='OHLC_Load'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UBL=pd.read_csv('Data/UBL.csv',index_col='Date',parse_dates=True)\n",
    "HBL=pd.read_csv('Data/HBL.csv',index_col='Date',parse_dates=True)\n",
    "NBP=pd.read_csv('Data/NBP.csv',index_col='Date',parse_dates=True)\n",
    "MEBL=pd.read_csv('Data/MEBL.csv',index_col='Date',parse_dates=True)\n",
    "UBL.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Data <a name='Plt'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.lineplot(data=UBL.Close,label='UBL')\n",
    "sns.lineplot(data=HBL.Close,label='HBL')\n",
    "sns.lineplot(data=MEBL.Close,label='MEBL')\n",
    "sns.lineplot(data=NBP.Close,label='NBP')\n",
    "plt.xlabel('Date',fontsize=15)\n",
    "plt.ylabel('Closing Price',fontsize=15)\n",
    "plt.title('Trend of Share Price of different KSE-30 Companies',fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping redundant feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UBL.drop('Symbol',axis=1,inplace=True)\n",
    "MEBL.drop('Symbol',axis=1,inplace=True)\n",
    "NBP.drop('Symbol',axis=1,inplace=True)\n",
    "HBL.drop('Symbol',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing column names in order to facilitate merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UBL.columns=['UBL_Open','UBL_High','UBL_Low','UBL_Close','UBL_Volume']\n",
    "MEBL.columns=['MEBL_Open','MEBL_High','MEBL_Low','MEBL_Close','MEBL_Volume']\n",
    "HBL.columns=['HBL_Open','HBL_High','HBL_Low','HBL_Close','HBL_Volume']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([UBL,MEBL,HBL],axis=1)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reversing Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data.iloc[::-1]\n",
    "data1=data1.reset_index()\n",
    "data1=data1.iloc[::-1]\n",
    "data1=data1.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Statistics <a name='desc'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=data1.loc[:,['UBL_Close','MEBL_Close','HBL_Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(data=data2.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "sns.boxplot(data=data2)\n",
    "plt.xlabel('Date',fontsize=15)\n",
    "plt.ylabel('Closing Price',fontsize=15)\n",
    "plt.title('Trend of Share Price of different KSE-30 Companies',fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferential Statistics <a name='Inf'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_coeff,p_val=stats.pearsonr(data2['UBL_Close'],data2['HBL_Close'])\n",
    "pearson_coeff,p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Conclusion:_**\n",
    "\n",
    "Since the p-value is <\n",
    "0.001, the correlation between UBL Stock Closing Price and HBL Stock Closing Price is statistically significant, and the linear relationship is quite strong (~0.834)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_coeff,p_val=stats.pearsonr(data2['UBL_Close'],data2['MEBL_Close'])\n",
    "pearson_coeff,p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Conclusion:_**\n",
    "\n",
    "Since the p-value is <\n",
    "0.001, the correlation between UBL Stock Closing Price and HBL Stock Closing Price is statistically significant, and the linear relationship is quite strong (~0.738)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pearson_coeff,p_val=stats.pearsonr(data2['MEBL_Close'],data2['HBL_Close'])\n",
    "pearson_coeff,p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading Frame Work <a name='Tf'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trader(X,nS1,nS3,share_price1,share_price2):\n",
    "    Amount_Gained=((nS3*share_price2)*.1)\n",
    "    Brocker_fee=((nS3*share_price2)*.1)*.3*.01\n",
    "    nS3=nS3-(nS3*.1)\n",
    "    X=X+Amount_Gained-Brocker_fee\n",
    "    Shares_bought=(.997*Amount_Gained)/share_price1\n",
    "    nS1=nS1+Shares_bought\n",
    "    X=X-(.997*Amount_Gained)\n",
    "    return X,nS1,nS3,Amount_Gained,-(Shares_bought*share_price1),Brocker_fee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactored Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock1(X,nS1,nS2,nS3,pS1,pS2,pS3,share_prices,Prediction,TN,low_thres,high_thres):\n",
    "    Trade_Occurred,Brocker_fee,Share1,Share2,Share3,temp1,temp2,temp3=False,0,0,0,0,0,0,0\n",
    "    if (pS3/TN)>low_thres and (pS2/TN)>low_thres:\n",
    "            X,nS1,nS3,temp1,temp2,temp3=trader(X,nS1,nS3,share_price[0],share_price[2])\n",
    "            Share3+=temp1\n",
    "            Share1+=temp2\n",
    "            Brocker_fee+=temp3\n",
    "            X,nS1,nS2,temp1,temp2,temp3=trader(X,nS1,nS2,share_price[0],share_price[1])\n",
    "            Share2+=temp1\n",
    "            Share1+=temp2\n",
    "            Brocker_fee+=temp3\n",
    "            Trade_Occurred=True\n",
    "    elif (model2_pred>model3_pred) and (pS3/TN)>low_thres:\n",
    "            X,nS1,nS3,temp1,temp2,temp3=trader(X,nS1,nS3,share_price[0],share_price[2])\n",
    "            Share3+=temp1\n",
    "            Share1+=temp2\n",
    "            Brocker_fee+=temp3\n",
    "            Trade_Occurred=True\n",
    "    elif (model3_pred>model2_pred) and (pS2/TN)>low_thres:\n",
    "            X,nS1,nS2,temp1,temp2,temp3=trader(X,nS1,nS2,share_price[0],share_price[1])\n",
    "            Share2+=temp1\n",
    "            Share1+=temp2\n",
    "            Brocker_fee+=temp3\n",
    "            Trade_Occurred=True\n",
    "    if model2_pred<0 and (pS2/TN)>low_thres:\n",
    "            X,nS1,nS2,temp1,temp2,temp3=trader(X,nS1,nS2,share_price[0],share_price[1])\n",
    "            Share2+=temp1\n",
    "            Share1+=temp2\n",
    "            Brocker_fee+=temp3\n",
    "            Trade_Occurred=True\n",
    "    if model3_pred<0 and (pS3/TN)>low_thres:\n",
    "            X,nS1,nS3,temp1,temp2,temp3=trader(X,nS1,nS3,share_price[0],share_price[2])   \n",
    "            Share3+=temp1\n",
    "            Share1+=temp2\n",
    "            Brocker_fee+=temp3\n",
    "            Trade_Occurred=True\n",
    "    return X,nS1,nS2,nS3,Trade_Occurred,Share1,Share2,Share3,Brocker_fee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock2(X,nS1,nS2,nS3,pS1,pS2,pS3,share_prices,Prediction,TN,low_thres,high_thres):\n",
    "    Trade_Occurred,Brocker_fee,Share1,Share2,Share3,temp1,temp2,temp3=False,0,0,0,0,0,0,0\n",
    "    if (pS3/TN)>low_thres and (pS2/TN)>low_thres:\n",
    "            X,nS2,nS3,temp1,temp2,temp3=trader(X,nS2,nS3,share_price[1],share_price[2])\n",
    "            Share3+=temp1\n",
    "            Share2+=temp2\n",
    "            Brocker_fee+=temp3\n",
    "            X,nS2,nS1,temp1,temp2,temp3=trader(X,nS2,nS1,share_price[1],share_price[0])\n",
    "            Share1+=temp1\n",
    "            Share2+=temp2\n",
    "            Brocker_fee+=temp3\n",
    "            Trade_Occurred=True\n",
    "    elif (model1_pred>model3_pred) and (pS3/TN)>low_thres:\n",
    "            X,nS2,nS3,temp1,temp2,temp3=trader(X,nS2,nS3,share_price[1],share_price[2])\n",
    "            Share3+=temp1\n",
    "            Share2+=temp2\n",
    "            Brocker_fee+=temp3\n",
    "            Trade_Occurred=True\n",
    "    elif (model3_pred>model2_pred) and (pS1/TN)>low_thres:\n",
    "            X,nS2,nS1,temp1,temp2,temp3=trader(X,nS2,nS1,share_price[1],share_price[0])\n",
    "            Share1+=temp1\n",
    "            Share2+=temp2\n",
    "            Brocker_fee+=temp3\n",
    "            Trade_Occurred=True\n",
    "    if model1_pred<0 and (pS1/TN)>low_thres:\n",
    "            X,nS2,nS1,temp1,temp2,temp3=trader(X,nS2,nS1,share_price[1],share_price[0])\n",
    "            Share1+=temp1\n",
    "            Share2+=temp2\n",
    "            Brocker_fee+=temp3\n",
    "            Trade_Occurred=True\n",
    "    if model3_pred<0 and (pS3/TN)>low_thres:\n",
    "            X,nS2,nS3,temp1,temp2,temp3=trader(X,nS2,nS3,share_price[1],share_price[2])\n",
    "            Share3+=temp1\n",
    "            Share2+=temp2\n",
    "            Brocker_fee+=temp3\n",
    "            Trade_Occurred=True\n",
    "    return X,nS1,nS2,nS3,Trade_Occurred,Share1,Share2,Share3,Brocker_fee    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock3(X,nS1,nS2,nS3,pS1,pS2,pS3,share_prices,Prediction,TN,low_thres,high_thres):\n",
    "    Trade_Occurred,Brocker_fee,Share1,Share2,Share3,temp1,temp2,temp3=False,0,0,0,0,0,0,0\n",
    "    if (pS3/TN)>low_thres and (pS2/TN)>low_thres:\n",
    "        X,nS3,nS1,temp1,temp2,temp3=trader(X,nS3,nS1,share_price[2],share_price[0])\n",
    "        Share1+=temp1\n",
    "        Share3+=temp2\n",
    "        Brocker_fee+=temp3\n",
    "        X,nS3,nS2,temp1,temp2,temp3=trader(X,nS3,nS2,share_price[2],share_price[1])\n",
    "        Share2+=temp1\n",
    "        Share3+=temp2\n",
    "        Brocker_fee+=temp3\n",
    "        Trade_Occurred=True\n",
    "    elif (model2_pred>model1_pred) and (pS1/TN)>low_thres:\n",
    "        X,nS3,nS1,temp1,temp2,temp3=trader(X,nS3,nS1,share_price[2],share_price[0])\n",
    "        Share1+=temp1\n",
    "        Share3+=temp2\n",
    "        Brocker_fee+=temp3\n",
    "        Trade_Occurred=True\n",
    "    elif (model1_pred>model2_pred) and (pS2/TN)>low_thres:\n",
    "        X,nS3,nS2,temp1,temp2,temp3=trader(X,nS3,nS2,share_price[2],share_price[1])\n",
    "        Share2+=temp1\n",
    "        Share3+=temp2\n",
    "        Brocker_fee+=temp3\n",
    "        Trade_Occurred=True\n",
    "    if model2_pred<0 and (pS2/TN)>low_thres:\n",
    "        X,nS3,nS2,temp1,temp2,temp3=trader(X,nS3,nS2,share_price[2],share_price[1])\n",
    "        Share2+=temp1\n",
    "        Share3+=temp2\n",
    "        Brocker_fee+=temp3\n",
    "        Trade_Occurred=True\n",
    "    if model1_pred<0 and (pS1/TN)>low_thres:\n",
    "        X,nS3,nS1,temp1,temp2,temp3=trader(X,nS3,nS1,share_price[2],share_price[0])\n",
    "        Share1+=temp1\n",
    "        Share3+=temp2\n",
    "        Brocker_fee+=temp3\n",
    "        Trade_Occurred=True\n",
    "    return X,nS1,nS2,nS3,Trade_Occurred,Share1,Share2,Share3,Brocker_fee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shares_trading(X,nS1,nS2,nS3,share_prices,Prediction,TN,low_thres,high_thres):\n",
    "    model1_pred,model2_pred,model3_pred=Prediction[0],Prediction[1],Prediction[2]\n",
    "    pS1,pS2,pS3=(nS1*share_prices[0]),(nS2*share_prices[1]),(nS3*share_prices[2])\n",
    "    Trade_Occurred,Brocker_fee,Share1,Share2,Share3=False,0,0,0,0\n",
    "    if (model1_pred>model2_pred and model1_pred>model3_pred) and (pS1/TN)<high_thres:\n",
    "        X,nS1,nS2,nS3,Trade_Occurred,Share1,Share2,Share3,Brocker_fee=stock1(X,nS1,nS2,nS3,pS1,pS2,pS3,\n",
    "                                                                      share_prices,Prediction,TN,\n",
    "                                                                      low_thres,high_thres)\n",
    "        return X,nS1,nS2,nS3,Trade_Occurred,Share1,Share2,Share3,Brocker_fee\n",
    "    \n",
    "    elif (model2_pred>model1_pred and model2_pred>model3_pred) and (pS2/TN)<high_thres:\n",
    "        X,nS1,nS2,nS3,Trade_Occurred,Share1,Share2,Share3,Brocker_fee=stock2(X,nS1,nS2,nS3,pS1,pS2,pS3,\n",
    "                                                                      share_prices,Prediction,TN,\n",
    "                                                                      low_thres,high_thres)\n",
    "        return X,nS1,nS2,nS3,Trade_Occurred,Share1,Share2,Share3,Brocker_fee\n",
    "    elif (model3_pred>model1_pred and model3_pred>model2_pred) and (pS3/TN)<high_thres:\n",
    "        X,nS1,nS2,nS3,Trade_Occurred,Share1,Share2,Share3,Brocker_fee=stock3(X,nS1,nS2,nS3,pS1,pS2,pS3,\n",
    "                                                                      share_prices,Prediction,TN,\n",
    "                                                                      low_thres,high_thres)\n",
    "        return X,nS1,nS2,nS3,Trade_Occurred,Share1,Share2,Share3,Brocker_fee\n",
    "    else:\n",
    "        Amount_Gained,Brocker_Fee=0,0\n",
    "        return X,nS1,nS2,nS3,Trade_Occurred,Share1,Share2,Share3,Brocker_fee\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Front End of Trading Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.rcParams['animation.html']='jshtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data1.index=data1.index.astype('str')\n",
    "fig=plt.figure(figsize=(10,6))\n",
    "ax=fig.add_subplot(111)\n",
    "i=0\n",
    "x,y=[],[]\n",
    "x1,y1=[],[]\n",
    "x2,y2=[],[]\n",
    "while True:\n",
    "    x.append(data1.index[i])\n",
    "    y.append(data1.UBL_Close[i])\n",
    "    x1.append(data1.index[i])\n",
    "    y1.append(data1.HBL_Close[i])\n",
    "    x2.append(data1.index[i])\n",
    "    y2.append(data1.MEBL_Close[i])\n",
    "    ax.plot(x,y,color='blue')\n",
    "    ax.plot(x1,y1,color='green')\n",
    "    ax.plot(x2,y2,color='purple')\n",
    "    plt.xticks(rotation=90)\n",
    "    ax.legend(['UBL','HBL','MEBL'],loc='upper left')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Stock_Price')\n",
    "    ax.set_title('Variations of Stock Prices over time')\n",
    "    plt.show()\n",
    "    fig.canvas.draw()\n",
    "    time.sleep(1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3=data1.reset_index()\n",
    "data3=data3.loc[0:,:]\n",
    "data3.reset_index(inplace=True)\n",
    "data3.drop('index',inplace=True,axis=1)\n",
    "data3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Data Frame to Record Files into Excel Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Acquired=pd.DataFrame({'Time_Stamp':['2009-06-18','2009-06-18'],'UBL_Shares':[0,162],'HBL_Shares':[0,92],'MEBL_Shares':[0,986],'Trade_Ocurred':[False,True],\n",
    "                            'UBL_Pred':[0,0],'HBL_Pred':[0,0],'MEBL_Pred':[0,0],'UBL_portfolio':[0,.33],\n",
    "                            'HBL_portfolio':[0,.33],'MEBL_portfolio':[0,.33],'Balance':[100000,109],'Brocker_Fee':[0,(99000*.3*.01*3)]\n",
    "                            ,'Share1_NetChange':[0,-33000],'Share2_NetChange':[0,-33000],'Share3_NetChange':[0,-33000],'TN':[100000,99109]})\n",
    "Data_Acquired['Time_Stamp']=pd.to_datetime(Data_Acquired['Time_Stamp'],format='%Y-%m-%d')\n",
    "Data_Acquired.to_csv('Trade_log.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Acquired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Testing <a name='Ut'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=100000\n",
    "nS1=math.floor((X*.33)/data3.loc[0,'UBL_Close'])\n",
    "nS2=math.floor((X*.33)/data3.loc[0,'HBL_Close'])\n",
    "nS3=math.floor((X*.33)/data3.loc[0,'MEBL_Close'])\n",
    "X-=X*.99+(891)\n",
    "X,nS1,nS2,nS3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=100000\n",
    "nS1=(X*.33)/data3.loc[0,'UBL_Close']\n",
    "nS2=(X*.33)/data3.loc[0,'HBL_Close']\n",
    "nS3=(X*.33)/data3.loc[0,'MEBL_Close']\n",
    "\n",
    "X-=X*.99+(891)\n",
    "low_thres=0.3\n",
    "high_thres=0.4\n",
    "for index in range(data3.shape[0]-1):\n",
    "    total_shares=nS1+nS2+nS3\n",
    "    model1_pred=data3.loc[index+1,'UBL_Close']-data3.loc[index,'UBL_Close']\n",
    "    model2_pred=data3.loc[index+1,'HBL_Close']-data3.loc[index,'HBL_Close']\n",
    "    model3_pred=data3.loc[index+1,'MEBL_Close']-data3.loc[index,'MEBL_Close']\n",
    "    prediction=[model1_pred,model2_pred,model3_pred]\n",
    "    \n",
    "    share_price=[data3.loc[index,'UBL_Close'],data3.loc[index,'HBL_Close'],data3.loc[index,'MEBL_Close']]\n",
    "    TN=(nS1*data3.loc[index,'UBL_Close'])+(nS2*data3.loc[index,'HBL_Close'])+(nS3*data3.loc[index,'MEBL_Close'])\n",
    "    \n",
    "    X,nS1,nS2,nS3,Trade_Occurred,Share1,Share2,Share3,Brocker_fee=shares_trading(X,nS1,nS2,nS3,\n",
    "                                                                          share_price,prediction,TN,low_thres,\n",
    "                                                                          high_thres)\n",
    "    \n",
    "    pS1,pS2,pS3=(nS1*data3.loc[index,'UBL_Close']),(nS2*data3.loc[index,'HBL_Close']),(nS3*data3.loc[index,'MEBL_Close'])\n",
    "    TN=X+(nS1*data3.loc[index,'UBL_Close'])+(nS2*data3.loc[index,'HBL_Close'])+(nS3*data3.loc[index,'MEBL_Close'])\n",
    "\n",
    "\n",
    "    with open('Trade_log.csv','a',newline='') as raw:\n",
    "        file_writer=csv.writer(raw)\n",
    "        file_writer.writerow([data3.loc[index,'Date'],math.floor(nS1),math.floor(nS2),math.floor(nS3),Trade_Occurred,model1_pred,model2_pred,model3_pred,\n",
    "                              pS1/TN,pS2/TN,pS3/TN,X,Brocker_fee,Share1,Share2,Share3,TN])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trade Log <a name='Tl'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=pd.read_csv('Trade_log.csv')\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pS1/100000,pS2/100000,pS3/100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investment Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_shares=nS1+nS2+nS3\n",
    "X,nS1/total_shares,nS2/total_shares,nS3/total_shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per Trade Data <a name='pt'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Names=['ATRL','bahl','EPCL','FCCL','LUCK','MCB','MLCF','NETSOL','NML',\n",
    "      'OGDC','PPL','PSO','SEARL','TRG']\n",
    "i,dataframes=0,[]\n",
    "for name in Names:\n",
    "    dataframes.append(pd.read_csv('../per_trade_data/'+name+'.txt',delimiter='|',index_col='TRADE_ENTRY_DATE',\n",
    "                        parse_dates=True))\n",
    "    dataframes[i].reset_index(inplace=True)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving DateTime Format <a name='dt'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Format(t):\n",
    "    return t[:1]+':'+t[1:3]+':'+t[3:5]+'.'+t[5:] if len(t)==9 else t[:2]+':'+t[2:4]+':'+t[4:6]+'.'+t[6:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Combined(date,time):\n",
    "    return date[:11]+Format(str(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Formated(row):\n",
    "    return Combined(str(row.TRADE_ENTRY_DATE),str(row.KATS_TIME))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Helper Function to improve datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Names=['ATRL','bahl','EPCL','FCCL','LUCK','MCB','MLCF','NETSOL','NML',\n",
    "      'OGDC','PPL','PSO','SEARL','TRG']\n",
    "i,dataframes=0,[]\n",
    "for i in range(14):\n",
    "    dataframes[i]['Date_Time']=dataframes[i].apply(Formated,axis='columns')\n",
    "    dataframes[i]['Date_Time']=pd.to_datetime(dataframes[i]['Date_Time'], infer_datetime_format=True)\n",
    "    dataframes[i].to_csv('../Modified_Data/Modified_'+Names[i]+'.csv',index='Date_Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../Modified_Data/Modified_ATRL.csv',parse_dates=True,index_col='Date_Time',infer_datetime_format=True)\n",
    "df.drop(['Unnamed: 0','KATS_TIME'],axis=1,inplace=True)\n",
    "df.columns=['TRADE_ENTRY_DATE','ATRL','TRADE_QTY','TRADE_RATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data and completing missing values <a name='Clean'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Names=['bahl','EPCL','FCCL','LUCK','MCB','MLCF','NETSOL','NML',\n",
    "      'OGDC','PPL','PSO','SEARL','TRG']\n",
    "df=pd.read_csv('../Modified_Data/Modified_ATRL.csv',parse_dates=True,index_col='Date_Time',infer_datetime_format=True)\n",
    "df.drop(['Unnamed: 0','KATS_TIME'],axis=1,inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "for i in range(len(Names)):\n",
    "    df1=pd.read_csv('../Modified_Data/Modified_'+Names[i]+'.csv',parse_dates=True,index_col='Date_Time',infer_datetime_format=True)\n",
    "    df1.drop(['Unnamed: 0','KATS_TIME'],axis=1,inplace=True)\n",
    "    df1.reset_index(inplace=True)\n",
    "    df1.columns=[Names[i]+'_DT',Names[i]+'_TRADE_DATE',Names[i],Names[i]+'_TRADE_QTY',Names[i]+'_TRADE_RATE']\n",
    "    df=pd.concat([df,df1],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['bahl_DT','EPCL_DT','FCCL_DT','LUCK_DT','MCB_DT','MLCF_DT','NETSOL_DT','NML_DT','OGDC_DT','PPL_DT',\n",
    "        'OGDC_DT','PPL_DT','PSO_DT','SEARL_DT','TRG_DT'],axis=1,inplace=True)\n",
    "df.drop(['bahl_TRADE_DATE','EPCL_TRADE_DATE','FCCL_TRADE_DATE','LUCK_TRADE_DATE','MCB_TRADE_DATE','MLCF_TRADE_DATE',\n",
    "         'NETSOL_TRADE_DATE','NML_TRADE_DATE','OGDC_TRADE_DATE','PPL_TRADE_DATE',\n",
    "        'OGDC_TRADE_DATE','PPL_TRADE_DATE','PSO_TRADE_DATE','SEARL_TRADE_DATE','TRG_TRADE_DATE'],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completing ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bahl.fillna('BAHL',inplace=True),df.EPCL.fillna('EPCL',inplace=True),df.FCCL.fillna('FCCL',inplace=True),\n",
    "df.LUCK.fillna('LUCK',inplace=True),df.MCB.fillna('MCB',inplace=True),\n",
    "df.MLCF.fillna('MLCF',inplace=True),df.NETSOL.fillna('NETSOL',inplace=True),df.NML.fillna('NML',inplace=True),\n",
    "df.OGDC.fillna('OGDC',inplace=True),df.PPL.fillna('PPL',inplace=True),\n",
    "df.PSO.fillna('PSO',inplace=True),df.SEARL.fillna('SEARL',inplace=True),df.TRG.fillna('TRG',inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    df.fillna(method ='bfill',inplace=True)\n",
    "    df.fillna(method ='ffill',inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Names=['ATRL','bahl','EPCL','FCCL','LUCK','MCB','MLCF','NETSOL','NML',\n",
    "      'OGDC','PPL','PSO','SEARL','TRG']\n",
    "df_ATRL=df.iloc[:,[0,1,2,3,4]]\n",
    "df_BAHL=df.iloc[:,[0,1,5,6,7]]\n",
    "df_EPCL=df.iloc[:,[0,1,8,9,10]]\n",
    "df_FCCL=df.iloc[:,[0,1,11,12,13]]\n",
    "df_LUCK=df.iloc[:,[0,1,14,15,16]]\n",
    "df_MCB=df.iloc[:,[0,1,17,18,19]]\n",
    "df_MLCF=df.iloc[:,[0,1,20,21,22]]\n",
    "df_NETSOL=df.iloc[:,[0,1,23,24,25]]\n",
    "df_NML=df.iloc[:,[0,1,26,27,28]]\n",
    "df_OGDC=df.iloc[:,[0,1,29,30,31]]\n",
    "df_PPL=df.iloc[:,[0,1,32,33,34]]\n",
    "df_PSO=df.iloc[:,[0,1,35,36,37]]\n",
    "df_SEARL=df.iloc[:,[0,1,38,39,40]]\n",
    "df_TRG=df.iloc[:,[0,1,41,42,43]]\n",
    "dataframes=[df_ATRL,df_BAHL,df_EPCL,df_FCCL,df_LUCK,df_MCB,df_MLCF,df_NETSOL,df_NML,df_OGDC,df_PPL,df_PSO,df_SEARL,\n",
    "           df_TRG]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Names=['ATRL','bahl','EPCL','FCCL','LUCK','MCB','MLCF','NETSOL','NML',\n",
    "      'OGDC','PPL','PSO','SEARL','TRG']\n",
    "i=0\n",
    "for i in range(14):\n",
    "    dataframes[i].to_csv('../Cleaned_Data/'+Names[i]+'.csv',index='Date_Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataCubes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading all the data into Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Into First loop\n",
      "Into  EPCL\n",
      "done  EPCL\n",
      "Into  FCCL\n",
      "done  FCCL\n",
      "Into  LUCK\n",
      "done  LUCK\n",
      "Into  MCB\n",
      "done  MCB\n",
      "Into  MLCF\n",
      "done  MLCF\n",
      "Into  NETSOL\n",
      "done  NETSOL\n",
      "Into  NML\n",
      "done  NML\n",
      "Into  OGDC\n",
      "done  OGDC\n",
      "Into  PPL\n",
      "done  PPL\n",
      "Into  PSO\n",
      "done  PSO\n",
      "Into  SEARL\n",
      "done  SEARL\n",
      "Into  TRG\n",
      "done  TRG\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_Time</th>\n",
       "      <th>TRADE_ENTRY_DATE</th>\n",
       "      <th>ID</th>\n",
       "      <th>TRADE_QTY</th>\n",
       "      <th>TRADE_RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-04-01 09:30:01.098700</td>\n",
       "      <td>2009-04-01</td>\n",
       "      <td>ATRL</td>\n",
       "      <td>100.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-04-01 09:30:01.098800</td>\n",
       "      <td>2009-04-01</td>\n",
       "      <td>ATRL</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-04-01 09:30:01.098900</td>\n",
       "      <td>2009-04-01</td>\n",
       "      <td>ATRL</td>\n",
       "      <td>100.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-04-01 09:30:01.099000</td>\n",
       "      <td>2009-04-01</td>\n",
       "      <td>ATRL</td>\n",
       "      <td>300.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-04-01 09:30:01.099100</td>\n",
       "      <td>2009-04-01</td>\n",
       "      <td>ATRL</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4302036</th>\n",
       "      <td>2019-04-15 15:28:45.005000</td>\n",
       "      <td>2019-04-15</td>\n",
       "      <td>TRG</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>21.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4302037</th>\n",
       "      <td>2019-04-15 15:28:51.000700</td>\n",
       "      <td>2019-04-15</td>\n",
       "      <td>TRG</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>21.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4302038</th>\n",
       "      <td>2019-04-15 15:28:51.002100</td>\n",
       "      <td>2019-04-15</td>\n",
       "      <td>TRG</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>21.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4302039</th>\n",
       "      <td>2019-04-15 15:29:15.005000</td>\n",
       "      <td>2019-04-15</td>\n",
       "      <td>TRG</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>21.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4302040</th>\n",
       "      <td>2019-04-15 16:07:13.000700</td>\n",
       "      <td>2019-04-15</td>\n",
       "      <td>TRG</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>21.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60228574 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Date_Time TRADE_ENTRY_DATE    ID  TRADE_QTY  \\\n",
       "0       2009-04-01 09:30:01.098700       2009-04-01  ATRL      100.0   \n",
       "1       2009-04-01 09:30:01.098800       2009-04-01  ATRL     1000.0   \n",
       "2       2009-04-01 09:30:01.098900       2009-04-01  ATRL      100.0   \n",
       "3       2009-04-01 09:30:01.099000       2009-04-01  ATRL      300.0   \n",
       "4       2009-04-01 09:30:01.099100       2009-04-01  ATRL     3700.0   \n",
       "...                            ...              ...   ...        ...   \n",
       "4302036 2019-04-15 15:28:45.005000       2019-04-15   TRG     4500.0   \n",
       "4302037 2019-04-15 15:28:51.000700       2019-04-15   TRG     4500.0   \n",
       "4302038 2019-04-15 15:28:51.002100       2019-04-15   TRG     4500.0   \n",
       "4302039 2019-04-15 15:29:15.005000       2019-04-15   TRG     4500.0   \n",
       "4302040 2019-04-15 16:07:13.000700       2019-04-15   TRG     4500.0   \n",
       "\n",
       "         TRADE_RATE  \n",
       "0              82.0  \n",
       "1              82.0  \n",
       "2              82.0  \n",
       "3              82.0  \n",
       "4              82.0  \n",
       "...             ...  \n",
       "4302036        21.9  \n",
       "4302037        21.9  \n",
       "4302038        21.9  \n",
       "4302039        21.9  \n",
       "4302040        21.9  \n",
       "\n",
       "[60228574 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('../Cleaned_Data/ATRL.csv',parse_dates=True,index_col='Date_Time',infer_datetime_format=True)\n",
    "df.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "df.columns=['TRADE_ENTRY_DATE','ID','TRADE_QTY','TRADE_RATE']\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "df1=pd.read_csv('../Cleaned_Data/bahl.csv',parse_dates=True,index_col='Date_Time',infer_datetime_format=True)\n",
    "df1.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "df1.columns=['TRADE_ENTRY_DATE','ID','TRADE_QTY','TRADE_RATE']\n",
    "df1.reset_index(inplace=True)\n",
    "df=pd.concat([df,df1])\n",
    "\n",
    "Names=['EPCL','FCCL','LUCK','MCB','MLCF','NETSOL','NML',\n",
    "      'OGDC','PPL','PSO','SEARL','TRG']\n",
    "print('Into First loop')\n",
    "\n",
    "for i in range(0,len(Names)):\n",
    "    print('Into ',Names[i])\n",
    "    df1=pd.read_csv('../Cleaned_Data/'+Names[i]+'.csv',parse_dates=True,index_col='Date_Time',infer_datetime_format=True)\n",
    "    df1.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "    df1.columns=['TRADE_ENTRY_DATE','ID','TRADE_QTY','TRADE_RATE']\n",
    "    df1.reset_index(inplace=True)\n",
    "    df=pd.concat([df,df1])\n",
    "    print('done ',Names[i])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping data to form datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df[:]\n",
    "df2=df1.groupby([df1.TRADE_ENTRY_DATE,df1.Date_Time.hour,df1.Date_Time.minute,df1.SYMBOL_CODE]).TRADE_RATE.agg(['max','min'])\n",
    "df2['TRADE_RATE']=df1.groupby([df1.TRADE_ENTRY_DATE,df1.Date_Time.hour,df1.Date_Time.minute]).TRADE_RATE.first()\n",
    "df2.columns=['HIGH','LOW','OPEN']\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df[:]\n",
    "df2=df1.groupby([df1.TRADE_ENTRY_DATE,df1.Date_Time.dt.hour,df1.Date_Time.dt.minute,df1.ID]).TRADE_RATE.agg(['min','max'])\n",
    "df2['OPEN']=df1.groupby([df1.TRADE_ENTRY_DATE,df1.Date_Time.dt.hour,df1.Date_Time.dt.minute,df1.ID]).TRADE_RATE.first()\n",
    "df2['CLOSE']=df1.groupby([df1.TRADE_ENTRY_DATE,df1.Date_Time.dt.hour,df1.Date_Time.dt.minute,df1.ID]).TRADE_RATE.last()\n",
    "df2.columns=['LOW','HIGH','OPEN','CLOSE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving DataCube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('File.csv')\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Gradient Boosted Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection,tree\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = df.index\n",
    "df['hour'] = df['date'].dt.hour\n",
    "df['dayofweek'] = df['date'].dt.dayofweek\n",
    "df['quarter'] = df['date'].dt.quarter\n",
    "df['month'] = df['date'].dt.month\n",
    "df['year'] = df['date'].dt.year\n",
    "df['dayofyear'] = df['date'].dt.dayofyear\n",
    "df['dayofmonth'] = df['date'].dt.day\n",
    "df['weekofyear'] = df['date'].dt.weekofyear\n",
    "    \n",
    "X = df[['hour','dayofweek','quarter','month','year',\n",
    "           'dayofyear','dayofmonth','weekofyear','Open','High','Low','Volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.Open=X.Open.astype('float')\n",
    "X.High=X.High.astype('float')\n",
    "X.Low=X.Low.astype('float')\n",
    "X.Volume=X.Volume.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data[['Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y=y.astype('float')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=model_selection.train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg = xgb.XGBRegressor(n_estimators=1000)\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.lineplot(data=yhat)\n",
    "sns.lineplot(data=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_squared_error(y_test,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
